#!/bin/bash

# ========================================================================
# AUTOSCALER MODEL - COMPREHENSIVE TESTING & VERIFICATION GUIDE
# ========================================================================
# This guide shows how to check if your autoscaler is working correctly
# ========================================================================

cat << 'EOF'

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ðŸ” AUTOSCALER MODEL - HOW TO CHECK IF IT'S WORKING          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Your model (autoscaler) works through these steps:
  1. Reads metrics from Prometheus every 30 seconds
  2. Calculates RPS (requests per second) for each service
  3. Compares RPS against thresholds
  4. Makes scaling decisions
  5. Updates Kubernetes deployment replicas

Let's verify each step is working!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ” LEVEL 1: BASIC HEALTH CHECK (30 seconds)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Check if autoscaler pod is running:

  kubectl get pods -l app=reactive-autoscaler

Expected output:
  NAME                                  READY   STATUS    RESTARTS
  reactive-autoscaler-6d96c9d9d-9gmqh   1/1     Running   0

If NOT running:
  â†’ Check: kubectl describe pod -l app=reactive-autoscaler
  â†’ Check: kubectl logs deployment/reactive-autoscaler

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Check if ConfigMap exists:

  kubectl get configmap autoscaler-config

Expected output:
  NAME                  DATA   AGE
  autoscaler-config     1      2m

If NOT found:
  â†’ Redeploy: kubectl apply -f config.yaml

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Check if RBAC permissions are set:

  kubectl get serviceaccount autoscaler
  kubectl get role autoscaler-role
  kubectl get rolebinding autoscaler-binding

Expected output: All three resources should exist

If NOT found:
  â†’ Redeploy: kubectl apply -f rbac.yaml

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ” LEVEL 2: CHECK LOGS FOR INITIALIZATION (1 minute)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

View initialization logs:

  kubectl logs deployment/reactive-autoscaler

Look for these messages (should appear in order):
  âœ“ "Autoscaler initialized"
  âœ“ "Monitoring X services"
  âœ“ "Prometheus: http://..."
  âœ“ "Collecting metrics from Prometheus"

Example expected output:
  2024-12-06 18:00:15 - INFO - ðŸš€ Autoscaler initialized
  2024-12-06 18:00:15 - INFO - Monitoring 2 services: [frontend, checkout]
  2024-12-06 18:00:15 - INFO - Prometheus: http://prometheus-server:80
  2024-12-06 18:00:45 - INFO - Collecting metrics from Prometheus

If you see ERRORS:
  âœ— "ConnectionError" â†’ Prometheus not reachable
  âœ— "ServiceAccount" â†’ RBAC permissions missing
  âœ— "ConfigMap" â†’ Config not found

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ” LEVEL 3: CHECK PROMETHEUS CONNECTION (2 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Get the autoscaler pod name:

  POD=$(kubectl get pod -l app=reactive-autoscaler -o jsonpath='{.items[0].metadata.name}')
  echo $POD

Test Prometheus connectivity:

  kubectl exec $POD -- curl -s http://prometheus-server:80/api/v1/query?query=up | head -20

Expected output: JSON response with Prometheus status
  {"status":"success","data":{"resultType":"vector",...

If FAILS (curl error):
  â†’ Check Prometheus service: kubectl get svc -l app.kubernetes.io/name=prometheus
  â†’ Check Prometheus pod: kubectl get pods -l app.kubernetes.io/name=prometheus
  â†’ Check network: kubectl exec $POD -- ping prometheus-server

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ” LEVEL 4: CHECK METRICS COLLECTION (3-5 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Watch logs for metric collection:

  kubectl logs -f deployment/reactive-autoscaler | grep -i "metrics\|rps\|collecting"

Expected output every 30 seconds:
  Collecting metrics...
  frontend RPS: 45.3
  checkout RPS: 12.1

If NO metrics appear:
  â†’ Services might not be emitting http_requests_total metric
  â†’ Check if services have /metrics endpoint
  â†’ Query Prometheus directly:
    kubectl exec $POD -- curl -s 'http://prometheus-server:80/api/v1/query?query=http_requests_total' | grep -o '"value"'

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ” LEVEL 5: CHECK SCALING DECISIONS (5-10 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Watch logs for scaling decisions:

  kubectl logs -f deployment/reactive-autoscaler | grep -E "UPSCALE|DOWNSCALE|BLOCKED"

Expected output when traffic increases:
  ðŸ”„ UPSCALE: frontend 2â†’3 | RPS: 75.2 >= 60.0
  ðŸ”„ UPSCALE: frontend 3â†’4 | RPS: 95.1 >= 90.0

Expected output when traffic decreases:
  ðŸ”„ DOWNSCALE: frontend 4â†’2 | RPS: 35.2 < 50.0
  ðŸ”„ DOWNSCALE: checkout 2â†’1 | RPS: 8.5 < 10.0

Expected blocking messages (cooldown period):
  â¸ï¸  BLOCKED: frontend | In cooldown: wait 42 seconds

If NO scaling decisions:
  â†’ No traffic being generated (generate traffic!)
  â†’ RPS not changing enough to trigger scaling
  â†’ Thresholds might be too high/low

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ§ª LEVEL 6: FULL END-TO-END TEST (10-15 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

This test verifies the complete workflow:

1ï¸âƒ£  Deploy a test application:

  kubectl create deployment frontend --image=nginx:latest --replicas=1
  kubectl expose deployment frontend --port=80 --target-port=80

2ï¸âƒ£  Check autoscaler is monitoring it:

  kubectl logs deployment/reactive-autoscaler | grep "frontend"

  Expected: "Monitoring X services: [frontend, ...]"

3ï¸âƒ£  Generate traffic to the service:

  # Terminal 1: Start load generator
  kubectl run -i --tty load-gen --rm --image=busybox --restart=Never -- /bin/sh
  
  # Inside pod, run:
  while true; do wget -q -O- http://frontend; done

4ï¸âƒ£  Watch scaling happen in real-time:

  # Terminal 2: Watch replicas
  kubectl get deployment frontend --watch

  # Terminal 3: Watch autoscaler logs
  kubectl logs -f deployment/reactive-autoscaler | grep -E "frontend|UPSCALE|DOWNSCALE"

5ï¸âƒ£  Expected sequence:

  Initial:
    frontend 1/1   (1 replica)
  
  After traffic starts (30-60 seconds):
    âœ“ Logs show: "frontend RPS: 120.5"
    âœ“ Logs show: "ðŸ”„ UPSCALE: frontend 1â†’2"
    âœ“ Deployment updates: frontend 2/2
  
  More traffic:
    âœ“ Logs show: "frontend RPS: 250.3"
    âœ“ Logs show: "ðŸ”„ UPSCALE: frontend 2â†’3"
    âœ“ Deployment updates: frontend 3/3

6ï¸âƒ£  Stop traffic and watch scaling down:

  # Ctrl+C in load generator pod
  
  After 1-2 minutes:
    âœ“ Logs show: "frontend RPS: 2.1 (decreasing)"
    âœ“ Logs show: "ðŸ”„ DOWNSCALE: frontend 3â†’2"
    âœ“ Deployment updates: frontend 2/2

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“Š QUICK HEALTH CHECK COMMANDS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

All in one command - quick status check:

  echo "=== POD STATUS ===" && \
  kubectl get pods -l app=reactive-autoscaler && \
  echo "" && \
  echo "=== RECENT LOGS ===" && \
  kubectl logs --tail=20 deployment/reactive-autoscaler && \
  echo "" && \
  echo "=== CONFIG ===" && \
  kubectl get configmap autoscaler-config -o jsonpath='{.data.config\.json}' | python3 -m json.tool | head -15

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“ˆ MONITORING DASHBOARD COMMANDS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Watch scaling in real-time (3 terminals):

  Terminal 1: kubectl logs -f deployment/reactive-autoscaler
  Terminal 2: kubectl get deployment --watch
  Terminal 3: kubectl top pod -l app=reactive-autoscaler

2. Filter for key events only:

  kubectl logs deployment/reactive-autoscaler | grep -E "UPSCALE|DOWNSCALE|ERROR|Monitoring|initialized"

3. Export logs for analysis:

  kubectl logs deployment/reactive-autoscaler > autoscaler.log
  grep "UPSCALE\|DOWNSCALE" autoscaler.log | tail -20

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ TROUBLESHOOTING - WHAT IF NOTHING IS HAPPENING?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Problem: Pod is running but logs are empty
  Solution: Check if metrics are being collected
  $ kubectl exec $POD -- curl -s 'http://prometheus-server:80/api/v1/query?query=http_requests_total'

Problem: Pod won't start
  Solution: Check pod description
  $ kubectl describe pod -l app=reactive-autoscaler
  $ kubectl logs deployment/reactive-autoscaler

Problem: Prometheus connection error
  Solution: Verify Prometheus is running
  $ kubectl get svc -l app.kubernetes.io/name=prometheus
  $ kubectl get pods -l app.kubernetes.io/name=prometheus

Problem: No services are being monitored
  Solution: Deploy a test service with metrics
  $ kubectl create deployment test --image=nginx:latest
  $ kubectl expose deployment test --port=80

Problem: Scaling happens but too fast/slow
  Solution: Check configuration
  $ kubectl get configmap autoscaler-config -o yaml
  Edit: cooldown_period, ema_alpha, rps_thresholds

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… VERIFICATION CHECKLIST - MARK THESE OFF
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Basic Health:
  â˜ Pod is running (kubectl get pods)
  â˜ Pod has 1/1 ready
  â˜ No restarts (RESTARTS = 0)
  â˜ Pod age is recent

Configuration:
  â˜ ConfigMap exists (kubectl get configmap)
  â˜ RBAC ServiceAccount exists
  â˜ RBAC Role exists
  â˜ RBAC RoleBinding exists

Prometheus Connection:
  â˜ Prometheus pod is running
  â˜ Prometheus service exists
  â˜ Autoscaler can connect to Prometheus
  â˜ Metrics are available in Prometheus

Metrics Collection:
  â˜ Logs show "Monitoring X services"
  â˜ Logs show periodic "Collecting metrics"
  â˜ Logs show RPS values for each service

Scaling Logic:
  â˜ When traffic increases: UPSCALE messages appear
  â˜ When traffic decreases: DOWNSCALE messages appear
  â˜ Kubernetes replicas actually update
  â˜ Cooldown period is respected (no rapid scaling)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸŽ¯ QUICK TEST SCENARIO (15 minutes)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

This is the fastest way to verify everything is working:

Step 1 (0m): Check health
  kubectl get pods -l app=reactive-autoscaler
  kubectl logs --tail=10 deployment/reactive-autoscaler

Step 2 (1m): Deploy test app
  kubectl create deployment my-app --image=nginx:latest --replicas=1
  kubectl expose deployment my-app --port=80

Step 3 (3m): Generate traffic (terminal 1)
  kubectl run -i --tty load --rm --image=busybox --restart=Never -- /bin/sh
  # Inside: while true; do wget -q -O- http://my-app; done

Step 4 (5m): Watch autoscaler decisions (terminal 2)
  kubectl logs -f deployment/reactive-autoscaler | grep -E "my-app|UPSCALE|DOWNSCALE"

Step 5 (7m): Watch Kubernetes updates (terminal 3)
  kubectl get deployment my-app --watch

Step 6 (10m): Stop traffic and watch scale-down
  # Ctrl+C in terminal 1

Expected Result:
  âœ“ Replicas increase (1 â†’ 2 â†’ 3)
  âœ“ Logs show UPSCALE messages
  âœ“ After stopping traffic, replicas decrease
  âœ“ Logs show DOWNSCALE messages

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“Š METRIC DETAILS TO LOOK FOR
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

In the logs, you should see patterns like:

1. RPS (Requests Per Second):
   "frontend RPS: 123.45"      â† High traffic
   "frontend RPS: 8.20"        â† Low traffic
   "frontend RPS: 0.0"         â† No traffic

2. Smoothed RPS (EMA):
   "frontend Smoothed RPS: 95.3"  â† Value is smoothed
   "frontend Smoothed RPS: 87.2"  â† Reacts to changes gradually

3. Scaling Decisions:
   "ðŸ”„ UPSCALE: frontend 1â†’2 | RPS 65.3 >= 60.0"
   "ðŸ”„ DOWNSCALE: frontend 2â†’1 | RPS 15.2 < 25.0"
   "â¸ï¸  BLOCKED: frontend | Cooldown: wait 30s"

4. Hysteresis Effect (prevents oscillation):
   Scale UP at: RPS >= 60.0
   Scale DOWN at: RPS < 25.0 (not 60.0)
   This prevents rapid up/down cycling

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸŽ“ UNDERSTANDING THE THRESHOLDS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Check your current thresholds:

  kubectl get configmap autoscaler-config -o jsonpath='{.data.config\.json}' | \
  python3 -c "import sys, json; data=json.load(sys.stdin); print(json.dumps(data['rps_thresholds'], indent=2))"

Default thresholds:
  {
    "1": [10, 0],        â† 1 pod handles: 0-10 RPS (up at 10, down at 0)
    "2": [30, 8],        â† 2 pods handle: 8-30 RPS (up at 30, down at 8)
    "3": [60, 25],       â† 3 pods handle: 25-60 RPS (up at 60, down at 25)
    "4": [100, 50],      â† 4 pods handle: 50-100 RPS (up at 100, down at 50)
    "5": [999999, 90]    â† 5+ pods handle: 90+ RPS (unlimited up)
  }

The key insight:
  - First number: Scale UP threshold
  - Second number: Scale DOWN threshold
  - Gap prevents rapid oscillation (hysteresis)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ”— PUTTING IT ALL TOGETHER
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Your model works like this:

  [Prometheus Metrics]
         â†“ (http_requests_total)
  [Autoscaler Pod]
         â†“ (queries every 30s)
  [Calculate RPS]
         â†“
  [Compare vs Thresholds]
         â†“
  [Make Decision: UP/DOWN/BLOCK]
         â†“
  [Update Kubernetes Deployment]
         â†“
  [Replicas Change]

To verify each step:
  1. Check Prometheus has metrics
  2. Check autoscaler logs show RPS values
  3. Check logs show UP/DOWN/BLOCK decisions
  4. Check kubectl shows replica count changing

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ’¡ TIPS FOR SUCCESS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Always monitor 3 terminals simultaneously:
   - Terminal 1: kubectl logs -f deployment/reactive-autoscaler
   - Terminal 2: kubectl get deployment --watch
   - Terminal 3: kubectl exec $POD -- watch -n 1 'curl -s http://prom:80/api/v1/query?query=rate(http_requests_total[1m])'

2. Generate sustained traffic (at least 2-3 minutes) before expecting scaling

3. Remember cooldown period - no scaling happens for 60 seconds after a scale event

4. Watch for smoothed RPS (EMA) not just raw RPS - it responds more gradually

5. Check timestamps in logs - if nothing happens for 5 minutes, something is wrong

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“ž QUICK REFERENCE - COPY & PASTE COMMANDS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Get pod name
POD=$(kubectl get pod -l app=reactive-autoscaler -o jsonpath='{.items[0].metadata.name}')

# Watch logs with filtering
kubectl logs -f deployment/reactive-autoscaler | grep -E "UPSCALE|DOWNSCALE|RPS|ERROR"

# Check all components
kubectl get pods,svc,configmap,role,rolebinding -l app

# Test prometheus
kubectl exec $POD -- curl -s http://prometheus-server:80/api/v1/query?query=up

# See current config
kubectl get configmap autoscaler-config -o yaml

# Restart autoscaler
kubectl rollout restart deployment/reactive-autoscaler

# View resources
kubectl top pod -l app=reactive-autoscaler
kubectl top nodes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸŽ‰ WHEN IT'S WORKING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

You'll see a pattern like this in logs:

  âœ“ "Autoscaler initialized"
  âœ“ "Monitoring 2 services: [frontend, checkout]"
  âœ“ Every 30 seconds: "frontend RPS: 45.2"
  âœ“ After 60 seconds of high traffic: "UPSCALE: frontend 1â†’2"
  âœ“ Kubernetes replicas increase (watch shows it)
  âœ“ After traffic decreases: "DOWNSCALE: frontend 2â†’1"
  âœ“ Kubernetes replicas decrease

Congratulations! Your autoscaler is working! ðŸŽŠ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EOF
